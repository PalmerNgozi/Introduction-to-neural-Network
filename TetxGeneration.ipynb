{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TetxGeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzpKyaSt/KbdrAj4wUPnq9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FlBPzOMMDi0M"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLWR9TkMOYpV",
        "outputId": "7931e047-8a76-4b17-855a-d3dd856cff74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print('lenght of test : {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ermZ8DdRQSzt",
        "outputId": "9798304c-d405-42f1-b38a-77437476f542"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenght of test : 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## encoding the text, here we encode each character with an integer\n",
        "\n",
        "vocab = sorted(set(text)) # sort all unique characters \n",
        "\n",
        "# create a mapping from unique characters to indices\n",
        "char_to_index = {u:i for i,u in enumerate(vocab)} # assigns lets say 0 to to n number of unique words stored in the vocab\n",
        "#reverse\n",
        "index_to_char = np.array(vocab)\n",
        "\n",
        "def text2int(text):\n",
        "  return np.array([char_to_index[a] for a in text])\n",
        "\n",
        "text_int = text2int(text)"
      ],
      "metadata": {
        "id": "jiAAj0BSQ48z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"text : \", text[:19])\n",
        "text_int1= text2int(text[:19]) # example to test the conversion\n",
        "\n",
        "print(\"Encoded text: \",text_int1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFJl8RctSiGD",
        "outputId": "716a873f-3221-4d80-9902-ff99d1309b89"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text :  First Citizen:\n",
            "Befo\n",
            "Encoded text:  [18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we were to go the other way around that is from int to text \n",
        "\n",
        "def int_to_text(integer):\n",
        "  try:\n",
        "    integer = integer.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return \"\".join(index_to_char[integer])\n",
        "\n",
        "print(int_to_text(text_int1)) # example to est the conversion "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4WJU8VsSqqP",
        "outputId": "e982e714-e13e-4005-e79a-e59470619854"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Befo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create training examples \n",
        "\n",
        "sequence_length = 100 \n",
        "ex_per_epoch =(len(text)//(sequence_length +1)) # we want the out put to contain the input word minus the first word and a new word at the end \n",
        "\n",
        "char_data = tf.data.Dataset.from_tensor_slices(text_int) # we want to slice the data int 101 words each.where 100 will be the training and 1 will be the precdiction \n",
        "\n",
        "seq = char_data.batch(sequence_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "iBMslYcPTjEm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the training example \n",
        "\n",
        "def split_target(bits):\n",
        "  inputs = bits[:-1]\n",
        "  labels = bits[1:]\n",
        "  return inputs, labels \n",
        "\n",
        "datasets = seq.map(split_target)"
      ],
      "metadata": {
        "id": "__lShTChWNa-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in datasets.take(2):\n",
        "  print('\\n\\nExample\\n')\n",
        "  print(\"Input\")\n",
        "  print(int_to_text(a))\n",
        "  print(\"\\nOutput\")\n",
        "  print(int_to_text(b))"
      ],
      "metadata": {
        "id": "YxrJ_I90W4Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make training batches \n",
        "\n",
        "batchSize =64\n",
        "vocabSize = len(vocab)\n",
        "embedding = 256\n",
        "\n",
        "rnnUnit = 1024\n",
        "\n",
        "##i just copied this from tim it makes sense but if you have a better way thats fine also share them \n",
        "\n",
        "bufferSize = 10000\n",
        "\n",
        "data = datasets.shuffle(bufferSize).batch(batchSize, drop_remainder = True)\n"
      ],
      "metadata": {
        "id": "RGew5YKLXSLo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model \n",
        "def model_build(vocabSize, embedding, rnnUnit,batchSize) :\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Embedding(vocabSize, embedding,batch_input_shape=[batchSize, None]),\n",
        "                              tf.keras.layers.LSTM(rnnUnit, return_sequences= True,\n",
        "                                                   stateful = True,\n",
        "                                                   recurrent_initializer = 'glorot_uniform'),\n",
        "                              tf.keras.layers.Dense(vocabSize\n",
        "                                                    )\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7KWnhG5ye_mX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_build(vocabSize, embedding, rnnUnit, batchSize)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tebv9w5GgPLJ",
        "outputId": "c5635466-00b7-4b98-e8f8-98201f8cae64"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HwZXbP1DgfQJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}